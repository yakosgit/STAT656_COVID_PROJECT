---
title: 'STAT656_COVID_Project'
output:
  html_document: default
---

# 1- Data Source Background, Discription and Loading

### Background:

 - COVID-19 Case Surveillance Public Use Data(of Deidentified Patient Case). It has 19 elements for all COVID-19 cases shared with CDC and includes demographics, geography, any exposure history, disease severity indicators and outcomes, and presence of any underlying medical conditions and risk behaviors.

 - The original data from (https://data.cdc.gov/Case-Surveillance/COVID-19-Case-Surveillance-Public-Use-Data-with-Ge/n8mc-b4w4) has ~85+ million rows and ~13GB file size
 
 - filtered data (https://data.cdc.gov/Case-Surveillance/COVID-19-Case-Surveillance-Public-Use-Data-with-Ge/n8mc-b4w4/data) is ~1.4+ million rows and ~200MB file size - removing (missing, NA, unknown) from the following columns:
 death_yn, age_group, hosp_yn,  underlying_conditions_yn
 
### Column Discription:

### 1- case_month
**The earlier of month the Clinical Date (date related to the illness or specimen collection) or the Date Received by CDC**

### 2- res_state
**State of residence**

### 3- state_fips_code
**State FIPS code**

### 4- res_county
**County of residence**

### 5- county_fips_code
**County FIPS code**

### 6- age_group
**Age group [0 - 17 years; 18 - 49 years; 50 - 64 years; 65 + years; Unknown; Missing; NA, if value suppressed for privacy protection.]**

### 7- sex
**Sex [Female; Male; Other; Unknown; Missing; NA, if value suppressed for privacy protection.]**

### 8- race
**Race [American Indian/Alaska Native; Asian; Black; Multiple/Other; Native Hawaiian/Other Pacific Islander; White; Unknown; Missing; NA, if value suppressed for privacy protection.]**

### 9- ethnicity
**Ethnicity [Hispanic; Non-Hispanic; Unknown; Missing; NA, if value suppressed for privacy protection.]**

### 10- case_positive_specimen_interval
**Weeks between earliest date and date of first positive specimen collection Number**

### 11- case_onset_interval
**Weeks between earliest date and date of symptom onset. Number**

### 12- process
**Under what process was the case first identified? [Clinical evaluation; Routine surveillance; Contact tracing of case patient; Multiple; Other; Unknown; Missing]**

### 13- exposure_yn
**In the 14 days prior to illness onset, did the patient have any of the following known exposures: domestic travel, international travel, cruise ship or vessel travel as a passenger or crew member, workplace, airport/airplane, adult congregate living facility (nursing, assisted living, or long-term care facility), school/university/childcare center, correctional facility, community event/mass gathering, animal with confirmed or suspected COVID-19, other exposure, contact with a known COVID-19 case? [Yes, Unknown, Missing]**

### 14- current_status
**What is the current status of this person? [Laboratory-confirmed case, Probable case]**

### 15- symptom_status
**What is the symptom status of this person? [Asymptomatic, Symptomatic, Unknown, Missing]**

### 16- hosp_yn
**Was the patient hospitalized? [Yes, No, Unknown, Missing]**

### 17- icu_yn
**Was the patient admitted to an intensive care unit (ICU)? [Yes, No, Unknown, Missing]**

### 18- death_yn
**Did the patient die as a result of this illness? [Yes; No; Unknown; Missing; NA, if value suppressed for privacy protection.]**

### 19- underlying_conditions_yn
**Did the patient have one or more of the underlying medical conditions and risk behaviors: diabetes mellitus, hypertension, severe obesity (BMI>40), cardiovascular disease, chronic renal disease, chronic liver disease, chronic lung disease, other chronic diseases, immunosuppressive condition, autoimmune condition, current smoker, former smoker, substance abuse or misuse, disability, psychological/psychiatric, pregnancy, other. [Yes, No, blank]**

### Loading Packages and Data:

```{r loadingPackages , results="hide"}
packs = c('dplyr','ggplot2', 'caret','corrplot', 'e1071','readr', 'pROC', 'lubridate')
invisible (lapply(packs,require,character.only=TRUE))
```

```{r loadingData , cache = TRUE}
#rm(list=ls())# Just to clean up the memory again

# "dataSetPath" is the path variable to the directory on your PC where you place the dataset csv files 

#Yako's Dataset Path
dataSetPath = '/home/yako/Desktop/TAMU_STAT/STAT656_Applied Analytics/STAT656FinalProject/Datasets'
#Laura's Dataset Path
#dataSetPath = '../'

dataSetName = 'COVID-19_Case_Surveillance_Public_Use_Data_with_Geography_Filterd.csv'
dataSet     = read_csv(file.path(dataSetPath,dataSetName))
head(dataSet, 3)
```

# 2- Exploratory Data Analysis
Items that usually need to be checked:

* Data structures
* Checking for missing data
* Converting qualitative features to dummy variables
* Extreme observations
* Skewness/transformations
* Correlations

### Checking The Overall Structure and Properties of The Dataset
```{r Check data structures}
str(dataSet)
```
### Checking Number of Unique Values
```{r Check number of unique values}
rbind(sapply(dataSet,function(x){ length(unique(x))}),
      sapply(dataSet,class))
```

### Checking For NA Values
```{r Check if any features have NA}
sapply(dataSet, function(x) sum(is.na(x)))
```
### Droping Unwanted Columns
Reason for dropping:
 - case_positive_specimen_interval, case_onset_interval, ethnicity: Too many NA values
 - state_fips_code,res_county, county_fips_code, res_state        : Geography related. Excluding from initial analysis
```{r Droping Unwanted Columns}
dataSet <- dataSet %>% select (-c(case_positive_specimen_interval, case_onset_interval,
                                state_fips_code, ethnicity, res_county, county_fips_code, res_state))
```
### Checking For NA Values Again
```{r Check if remaining features have NA and cleaning them}
sapply(dataSet, function(x) sum(is.na(x)))

#filtering out all these NAs
dataSet <- dataSet %>% filter(!is.na(age_group) & !is.na(sex) & !is.na(race))
sapply(dataSet, function(x) sum(is.na(x)))
```
### Checking For Other Types of Missing Values 
```{r Generating frquency tables}
# Extracting features that have "character" or "factor" type
catFteaures = names(dataSet[, sapply(dataSet, class) %in% c('character', 'factor')])

# Loop through selected categorical features and print frequency tables
for (colname in catFteaures){
  print(table(dataSet[colname]))
  print("------------------------------")
}
```
```{r removing other types of missing values}
# Based on the tables above, some features having missing values encoded as ("Missing", "Other", "Unknown")
# we are going to remove those observations from the dataset
dataSet <- dataSet %>% 
  filter(!(sex %in% c("Missing", "Other", "Unknown")) & 
           !(race %in% c("Missing", "Other", "Unknown")) &
           !(process %in% c("Missing", "Other", "Unknown")) &
           !(symptom_status %in% c("Missing", "Other", "Unknown")) &
           !(icu_yn %in% c("Missing", "Other", "Unknown"))) 

# we also notice the feature "exposure_yn" only contains some "yes" values and the rest are all "Missing" or "Unknown" - therefore we decided to remove this feature too   
dataSet <- dataSet %>% select (-c(exposure_yn))
```

```{r check frquency table again}
catFteaures = names(dataSet[, sapply(dataSet, class) %in% c('character', 'factor')])
for (colname in catFteaures){
  print(table(dataSet[colname]))
  print("------------------------------")
}
```

### Creating conditional frequency plots and frequency tables
- Here we build a function to loop through the categorical features and plot frequency charts of their levels conditioned on the levels of our response variable
```{r plot feature, fig.align="center", fig.width = 12, , cache = TRUE}
require(gridExtra)
theme_update(plot.title = element_text(hjust = 0.5))

# Loop through selected categorical features and plot 
for (colname in catFteaures) {
  
  plot1 = ggplot(filter(dataSet,death_yn == "No" ), aes(x=reorder(.data[[colname]], .data[[colname]], function(x)-length(x)))) + geom_bar(fill="#3A5795") +  labs(x=colname) + labs(title = paste("Counts of", colname, "when:", "\n", "death_yn" , "=", "No" ))
  
  plot2 = ggplot(filter(dataSet,death_yn == "Yes" ), aes(x=reorder(.data[[colname]], .data[[colname]], function(x)-length(x)))) + geom_bar(fill="#c00000") +  labs(x=colname) + labs(title = paste("Counts of", colname, "when:", "\n", "death_yn" , "=", "Yes" ))
  
  grid.arrange(plot1, plot2, ncol=2)
}

```

Note from Laura: This underlying_conditions_yn column might be problematic

# Building Models:

### Train/Test Data spliting:

```{r data spliting}
#partition data into train / test split
set.seed(13)
trainingDataIndex <- createDataPartition(dataSet$death_yn, p=.7, list=FALSE)
trainingData <- dataSet[trainingDataIndex,]
testingData <- dataSet[-trainingDataIndex,]

#split predictors and supervisor variable
Xtrain <- select(trainingData, -death_yn)
Xtest  <- select(testingData, -death_yn)
Ytrain <- factor(select(trainingData, death_yn) %>% unlist())
Ytest  <- factor(select(testingData, death_yn) %>% unlist())
```

```{r catagorical feature dummy encoding}
#train dummy model and apply to predictors
#NOTE: this needs to be changed if we end up using some predictors that are not categorical
dummyModel <- dummyVars(~ ., data= Xtrain, fullRank = TRUE)

XtrainFull = predict(dummyModel, Xtrain)
XtestFull = predict(dummyModel, Xtest)

#We want to be explicit about what is the event and what is not, so we need to relevel
#NOTE: I'm not sure about this, but I think we DON'T want the event as the reference category. This may be incorrect
YtrainRelevel = relevel(Ytrain, ref = 'No')
YtestRelevel = relevel(Ytest, ref = 'No')
```

### Applying Logistic Regression Model:
```{r logistic regression model}
#training logistic regression model
trControl = trainControl(method = 'none')
outLogistic = train(x = XtrainFull, y = YtrainRelevel,
                    method = 'glm', trControl = trControl)

YhatTestProbLR = predict(outLogistic, XtestFull, type = 'prob')

```

```{r ROC Curve of logistic regression model}
#generating the roc curve
rocCurveLR = roc(Ytest, YhatTestProbLR$Yes)

#plot the roc
plot(rocCurveLR, legacy.axes=TRUE)

rocCurveLR$auc

```

```{r confusion matrix logistic regression model}
#find threshold by setting based on sensitivity or specificity
thresholdsLR = rocCurveLR$thresholds
pt8 = max(which(rocCurveLR$sensitivities >= 0.80) )
thresholdLR = thresholdsLR[pt8]
specificityLR = rocCurveLR$specificities[pt8]
sensitivityLR = rocCurveLR$sensitivities[pt8]

YhatTestThreshLR = ifelse(YhatTestProbLR$Yes > thresholdLR, 'Yes', 'No') %>% as.factor

confusionMatrixOutLR = confusionMatrix(reference = YtestRelevel, data = YhatTestThreshLR, positive = "Yes")
confusionMatrixOutLR
```

### Applying Logistic Elastic Net Model:
```{r logistic elastic net , cache = TRUE}
set.seed(13)
K            = 10
trainControl = trainControl(method = "cv", number = K)
tuneGrid     = expand.grid('alpha'=c(0,.25,.5,.75,1),'lambda' = seq(00, .001, length.out = 30))

elasticOut = train(x = XtrainFull, y = YtrainRelevel,
                   method = "glmnet", 
                   trControl = trainControl, tuneGrid = tuneGrid)

```

```{r logistic elastic net best tune}
#starting to look at the output from the model
elasticOut$finalModel$beta[,1:6]

#best tune from the model
elasticOut$bestTune

```

```{r logistic elastic net retrain with best tune}
#re-train the model using the parameters from the best tune
require(glmnet)
glmnetOut      = glmnet(x = as.matrix(XtrainFull), y = YtrainRelevel, s=elasticOut$bestTune$alpha, 
                        family = 'binomial', standardize = FALSE)
probHatTestGlmnet    = predict(glmnetOut, XtestFull, s=elasticOut$bestTune$lambda, type='response')
YhatTestGlmnet = ifelse(probHatTestGlmnet > 0.035, 'Yes', 'No')
```

```{r logistic elastic net4}
#looking at the coefficients from the best tune
betaHatGlmnet = coef(glmnetOut, s=elasticOut$bestTune$lambda)
betaHatGlmnet

#get the accuracy 
mean(YhatTestGlmnet == YtestRelevel)
```

```{r logistic elastic net ROC Curve}
#plot ROC curve and get AUC
probHatTestGlmnet = predict(elasticOut, XtestFull, s=elasticOut$bestTune$lambda, type = 'prob')
rocOutGlmnet = roc(response = YtestRelevel, probHatTestGlmnet$Yes)
plot(rocCurveLR, legacy.axes=TRUE)
plot(rocOutGlmnet, col = 'red', add = TRUE)

# AUC Logistic Regression
rocCurveLR$auc
# AUC Logistic Elastic Net
rocOutGlmnet$auc

```

```{r logistic elastic net confusion matrix}
confusionMatrixOutGlmnet = confusionMatrix(reference = YtestRelevel, data = as.factor(YhatTestGlmnet), positive = "Yes")
confusionMatrixOutGlmnet
```


```{r knit stop}
knitr::knit_exit()
```

# Loading in Vaccination Data as a potential predictor

```{r load in the vaccination data , cache = TRUE}
# vaxSetPathL = '../' Note from Yako: lets use same "dataSetPath" variable name for all so that we don't have to change in through out the code 
vaxSetName = 'COVID-19_Vaccinations_in_the_United_States_County.csv'
vaxSet     = read_csv(file.path(dataSetPath,vaxSetName))
```

```{r filtering columns}
#filtering out most of the columns and just keeping what we need
vaxSet = vaxSet %>% select(c(Date, FIPS, Series_Complete_Pop_Pct, Census2019, Census2019_65PlusPop))

```


```{r formatting date to fit our COVID case dataset}
vaxSet$Day = as.numeric(format(as.Date(vaxSet$Date,format="%m/%d/%Y"), format = "%d"))
vaxSet$Date = format(as.Date(vaxSet$Date,format="%m/%d/%Y"), format = "%Y-%m")
```

I'm going to take the number from the end of the month in order to get it to work with our data

```{r group by for each month}
vaxSet = vaxSet %>% group_by(Date, FIPS) %>% summarize(Series_Complete_Pop_Pct = max(Series_Complete_Pop_Pct),
                                                       Census2019 = max(Census2019),
                                                       Census2019_65PlusPop = max(Census2019_65PlusPop))
```

```{r adjust date from original dataset}
#adding the first to these dates so that we can use this as a date
dataSet$vax_data_month = as.Date(paste(dataSet$case_month,"-01",sep=""))
```

```{r adjust date from vax dataset}
#this gives you the date where the vax data is considered to be valid 
vaxSet$Date = as.Date(paste(vaxSet$Date,"-01",sep="")) %m+% months(1)
```


Joining in the vaccination data and adding a roll-out indicator
```{r}
#join where the date of the case is in the month where vaccination percentage is valid
fullSet = dataSet %>% left_join(vaxSet, by=c('county_fips_code' = 'FIPS', 'vax_data_month' = 'Date'))

#zero out entries before there was widespread vaccination roll-out
fullSet$Series_Complete_Pop_Pct = ifelse(fullSet$vax_data_month <= '2020-12-31', 0, fullSet$Series_Complete_Pop_Pct)

#create an indicator variable for vaccination roll-out
fullSet$vax_rollout_indicator = ifelse(fullSet$vax_data_month <= '2020-12-31', 0, 1)
```

```{r}

```

# Taking the states and grouping them into regions for potential predictors

```{r}
#filtering out Guam observations
fullSet = fullSet %>% filter(res_state != 'GU', res_state != 'PR', res_state != 'VI')

#Using the census-bureau designations: https://en.wikipedia.org/wiki/List_of_regions_of_the_United_States#Census_Bureau-designated_regions_and_divisions

fullSet$region = ifelse(fullSet$res_state %in% c('CT', 'ME', 'VT', 'NH', 'VT', 'MA', 'RI', 'NY', 'PA', 'NJ'), 'NorthEast',
                        ifelse(fullSet$res_state %in% c('IL', 'IN', 'MI', 'OH', 'WI', 'IA', 'KS', 'MN', 'MO', 'NE', 'ND', 'SD'), 'Midwest',
                               ifelse(fullSet$res_state %in% c('DE', 'FL', 'GA', 'MD', 'NC', 'SC', 'VA', 'DC', 'WV', 'AL', 'KY', 'MS', 'TN', 'AR', 'LA', 'OK', 'TX'), 'South',
                                      ifelse(fullSet$res_state %in% c('AZ', 'CO', 'ID', 'MT', 'NV', 'NM', 'UT', 'WY', 'AK', 'CA', 'HI', 'OR', 'WA'), 'West', 'N/A'))))

```

