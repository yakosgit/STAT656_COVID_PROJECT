---
title: 'STAT656_COVID_Project'
output:
  html_document: default
---



# **1- Data Source Background, Discription and Loading**

### 1.1 Background:

 - This project explores COVID-19 Case Surveillance Public Use Data(of Deidentified Patient Case). The Dataset has 19 elements for all COVID-19 cases shared with CDC and includes demographics, geography, any exposure history, disease severity indicators and outcomes, and presence of any underlying medical conditions and risk behaviors.
 
 - The main scientific question we are trying to answer is whether a COVID death can be predicted and how accurately by using features/factors/signals related to each case as predictors in multiple different classification models and techniques. We are also interested in finding which factor(s) have the most impact (significance) in determining whether a COVID case would result in death or not
 
 - As we continue to work with our model, we plan on doing additional feature engineering and potentially bringing data corresponding to vaccination prevalence in the patientâ€™s community and additional information about pre-existing conditions

 - The original data from (https://data.cdc.gov/Case-Surveillance/COVID-19-Case-Surveillance-Public-Use-Data-with-Ge/n8mc-b4w4) has ~85+ million rows and ~13GB file size
 
 - filtered data (https://data.cdc.gov/Case-Surveillance/COVID-19-Case-Surveillance-Public-Use-Data-with-Ge/n8mc-b4w4/data) is ~1.4+ million rows and ~200MB file size - removing (missing, NA, unknown) from the following columns: **death_yn, age_group, hosp_yn,  underlying_conditions_yn**
 
### 1.2 Column Discription:

#### 1- case_month
**The earlier of month the Clinical Date (date related to the illness or specimen collection) or the Date Received by CDC**

#### 2- res_state
**State of residence**

#### 3- state_fips_code
**State FIPS code**

#### 4- res_county
**County of residence**

#### 5- county_fips_code
**County FIPS code**

#### 6- age_group
**Age group [0 - 17 years; 18 - 49 years; 50 - 64 years; 65 + years; Unknown; Missing; NA, if value suppressed for privacy protection.]**

#### 7- sex
**Sex [Female; Male; Other; Unknown; Missing; NA, if value suppressed for privacy protection.]**

#### 8- race
**Race [American Indian/Alaska Native; Asian; Black; Multiple/Other; Native Hawaiian/Other Pacific Islander; White; Unknown; Missing; NA, if value suppressed for privacy protection.]**

#### 9- ethnicity
**Ethnicity [Hispanic; Non-Hispanic; Unknown; Missing; NA, if value suppressed for privacy protection.]**

#### 10- case_positive_specimen_interval
**Weeks between earliest date and date of first positive specimen collection Number**

#### 11- case_onset_interval
**Weeks between earliest date and date of symptom onset. Number**

#### 12- process
**Under what process was the case first identified? [Clinical evaluation; Routine surveillance; Contact tracing of case patient; Multiple; Other; Unknown; Missing]**

#### 13- exposure_yn
**In the 14 days prior to illness onset, did the patient have any of the following known exposures: domestic travel, international travel, cruise ship or vessel travel as a passenger or crew member, workplace, airport/airplane, adult congregate living facility (nursing, assisted living, or long-term care facility), school/university/childcare center, correctional facility, community event/mass gathering, animal with confirmed or suspected COVID-19, other exposure, contact with a known COVID-19 case? [Yes, Unknown, Missing]**

#### 14- current_status
**What is the current status of this person? [Laboratory-confirmed case, Probable case]**

#### 15- symptom_status
**What is the symptom status of this person? [Asymptomatic, Symptomatic, Unknown, Missing]**

#### 16- hosp_yn
**Was the patient hospitalized? [Yes, No, Unknown, Missing]**

#### 17- icu_yn
**Was the patient admitted to an intensive care unit (ICU)? [Yes, No, Unknown, Missing]**

#### 18- death_yn
**Did the patient die as a result of this illness? [Yes; No; Unknown; Missing; NA, if value suppressed for privacy protection.]**

#### 19- underlying_conditions_yn
**Did the patient have one or more of the underlying medical conditions and risk behaviors: diabetes mellitus, hypertension, severe obesity (BMI>40), cardiovascular disease, chronic renal disease, chronic liver disease, chronic lung disease, other chronic diseases, immunosuppressive condition, autoimmune condition, current smoker, former smoker, substance abuse or misuse, disability, psychological/psychiatric, pregnancy, other. [Yes, No, blank]**

### 1.3 Loading Packages and Data:

```{r loadingPackages , results="hide"}
packs = c('dplyr','ggplot2', 'caret','corrplot', 'e1071','readr', 'pROC', 'lubridate')
invisible (lapply(packs,require,character.only=TRUE))
```

```{r loadingData , cache = TRUE}
#rm(list=ls())# Just to clean up the memory again

# "dataSetPath" is the path variable to the directory on your PC where you place the dataset csv files 

#Yako's Dataset Path
dataSetPath = '/home/yako/Desktop/TAMU_STAT/STAT656_Applied Analytics/STAT656FinalProject/Datasets'
#Laura's Dataset Path
#dataSetPath = '../'

dataSetName = 'COVID-19_Case_Surveillance_Public_Use_Data_with_Geography_Filterd.csv'
dataSet     = read_csv(file.path(dataSetPath,dataSetName))
head(dataSet, 3)
```

# **2- Exploratory Data Analysis**
Items that usually need to be checked:

* Data structures
* Checking for missing data
* Converting qualitative features to dummy variables
* Extreme observations
* Skewness/transformations
* Correlations

### 2.1 Checking The Overall Structure and Properties of The Dataset
```{r Check data structures}
str(dataSet)
```
### 2.2 Checking Number of Unique Values
```{r Check number of unique values}
rbind(sapply(dataSet,function(x){ length(unique(x))}),
      sapply(dataSet,class))
```

### 2.3 Checking For NA Values
```{r Check if any features have NA}
sapply(dataSet, function(x) sum(is.na(x)))
```
### 2.3.2 adding in regional coding

```{r}
#filtering out Guam observations
dataSet = dataSet %>% filter(res_state != 'GU', res_state != 'PR', res_state != 'VI')

#Using the census-bureau designations: https://en.wikipedia.org/wiki/List_of_regions_of_the_United_States#Census_Bureau-designated_regions_and_divisions

dataSet$region = ifelse(dataSet$res_state %in% c('CT', 'ME', 'VT', 'NH', 'VT', 'MA', 'RI', 'NY', 'PA', 'NJ'), 'NorthEast',
                        ifelse(dataSet$res_state %in% c('IL', 'IN', 'MI', 'OH', 'WI', 'IA', 'KS', 'MN', 'MO', 'NE', 'ND', 'SD'), 'Midwest',
                               ifelse(dataSet$res_state %in% c('DE', 'FL', 'GA', 'MD', 'NC', 'SC', 'VA', 'DC', 'WV', 'AL', 'KY', 'MS', 'TN', 'AR', 'LA', 'OK', 'TX'), 'South',
                                      ifelse(dataSet$res_state %in% c('AZ', 'CO', 'ID', 'MT', 'NV', 'NM', 'UT', 'WY', 'AK', 'CA', 'HI', 'OR', 'WA'), 'West', 'N/A'))))

```


### 2.4 Droping Unwanted Columns
Reason for dropping:

 - case_positive_specimen_interval, case_onset_interval, ethnicity: Too many NA values
 
 - state_fips_code,res_county, county_fips_code, res_state        : Geography related. Excluding from initial analysis
```{r Droping Unwanted Columns}
dataSet <- dataSet %>% select (-c(case_positive_specimen_interval, case_onset_interval,
                                state_fips_code, ethnicity, res_county, res_state))
```
### 2.5 Checking For NA Values Again
```{r Check if remaining features have NA and cleaning them}
sapply(dataSet, function(x) sum(is.na(x)))

#filtering out all these NAs
dataSet <- dataSet %>% filter(!is.na(age_group) & !is.na(sex) & !is.na(race) & !is.na(county_fips_code))
sapply(dataSet, function(x) sum(is.na(x)))
```
### 2.6 Checking For Other Types of Missing Values 
```{r Generating frquency tables}
# Extracting features that have "character" or "factor" type
catFteaures = names(dataSet[, sapply(dataSet, class) %in% c('character', 'factor')])

# Loop through selected categorical features and print frequency tables
for (colname in catFteaures){
  print(table(dataSet[colname]))
  print("------------------------------")
}
```
```{r removing other types of missing values}
# Based on the tables above, some features having missing values encoded as ("Missing", "Other", "Unknown")
# we are going to remove those observations from the dataset
dataSet <- dataSet %>% 
  filter(!(sex %in% c("Missing", "Other", "Unknown")) & 
           !(race %in% c("Missing", "Other", "Unknown")) &
           !(process %in% c("Missing", "Other", "Unknown")) &
           !(symptom_status %in% c("Missing", "Other", "Unknown")) &
           !(icu_yn %in% c("Missing", "Other", "Unknown"))) 

# we also notice the feature "exposure_yn" only contains some "yes" values and the rest are all "Missing" or "Unknown" - therefore we decided to remove this feature too   
dataSet <- dataSet %>% select (-c(exposure_yn))
```

```{r check frquency table again}
catFteaures = names(dataSet[, sapply(dataSet, class) %in% c('character', 'factor')])
for (colname in catFteaures){
  print(table(dataSet[colname]))
  print("------------------------------")
}
```

### 2.7 Creating conditional frequency plots and frequency tables
- Here we build a function to loop through the categorical features and plot frequency charts of their levels conditioned on the levels of our response variable
```{r plot feature, fig.align="center", fig.width = 12, , cache = TRUE}
require(gridExtra)
theme_update(plot.title = element_text(hjust = 0.5))

# Loop through selected categorical features and plot 
for (colname in catFteaures) {
  
  plot1 = ggplot(filter(dataSet,death_yn == "No" ), aes(x=reorder(.data[[colname]], .data[[colname]], function(x)-length(x)))) + geom_bar(fill="#3A5795") +  labs(x=colname) + labs(title = paste("Counts of", colname, "when:", "\n", "death_yn" , "=", "No" ))
  
  plot2 = ggplot(filter(dataSet,death_yn == "Yes" ), aes(x=reorder(.data[[colname]], .data[[colname]], function(x)-length(x)))) + geom_bar(fill="#c00000") +  labs(x=colname) + labs(title = paste("Counts of", colname, "when:", "\n", "death_yn" , "=", "Yes" ))
  
  grid.arrange(plot1, plot2, ncol=2)
}

```

Note from Laura: This underlying_conditions_yn column might be problematic

# Loading in Vaccination Data as a potential predictor

```{r load in the vaccination data , cache = TRUE}
# vaxSetPathL = '../' Note from Yako: lets use same "dataSetPath" variable name for all so that we don't have to change in through out the code 
vaxSetName = 'COVID-19_Vaccinations_in_the_United_States_County.csv'
vaxSet     = read_csv(file.path(dataSetPath,vaxSetName))
```

```{r filtering columns}
#filtering out most of the columns and just keeping what we need
vaxSet = vaxSet %>% select(c(Date, FIPS, Series_Complete_Pop_Pct, Census2019, Census2019_65PlusPop))

```


```{r formatting date to fit our COVID case dataset}
vaxSet$Day = as.numeric(format(as.Date(vaxSet$Date,format="%m/%d/%Y"), format = "%d"))
vaxSet$Date = format(as.Date(vaxSet$Date,format="%m/%d/%Y"), format = "%Y-%m")
```

I'm going to take the number from the end of the month in order to get it to work with our data

```{r group by for each month}
vaxSet = vaxSet %>% group_by(Date, FIPS) %>% summarize(Series_Complete_Pop_Pct = max(Series_Complete_Pop_Pct),
                                                       Census2019 = max(Census2019),
                                                       Census2019_65PlusPop = max(Census2019_65PlusPop))
```

```{r adjust date from original dataset}
#adding the first to these dates so that we can use this as a date
dataSet$vax_data_month = as.Date(paste(dataSet$case_month,"-01",sep=""))
```

```{r adjust date from vax dataset}
#this gives you the date where the vax data is considered to be valid 
vaxSet$Date = as.Date(paste(vaxSet$Date,"-01",sep="")) %m+% months(1)
```


Joining in the vaccination data and adding a roll-out indicator
```{r}
#join where the date of the case is in the month where vaccination percentage is valid
fullSet = dataSet %>% left_join(vaxSet, by=c('county_fips_code' = 'FIPS', 'vax_data_month' = 'Date'))

#zero out entries before there was widespread vaccination roll-out
fullSet$Series_Complete_Pop_Pct = ifelse(fullSet$vax_data_month <= '2020-12-31', 0, fullSet$Series_Complete_Pop_Pct)

#create an indicator variable for vaccination roll-out
#fullSet$vax_rollout_indicator = ifelse(fullSet$vax_data_month <= '2020-12-31', 0, 1)
```

```{r}
dataSet = fullSet %>% select(-c(county_fips_code, Census2019, Census2019_65PlusPop, vax_data_month))
```


# **3- Building Models**

### 2.1 Train/Test Data spliting:

```{r data spliting}
#partition data into train / test split
set.seed(13)
trainingDataIndex <- createDataPartition(dataSet$death_yn, p=.7, list=FALSE)
trainingData <- dataSet[trainingDataIndex,]
testingData <- dataSet[-trainingDataIndex,]

#downsampling the training data
#trainingDataNo = trainingData %>% filter(death_yn == 'No')
#trainingDataYes = trainingData %>% filter(death_yn == 'Yes')

#split predictors and supervisor variable
Xtrain <- select(trainingData, -death_yn)
Xtest  <- select(testingData, -death_yn)
# ?? Note: do we need to convert X to factors as well like the example below from lectures?
#Xtrain = select(Xtrain, MONTH, OP_UNIQUE_CARRIER) %>% mutate_all(factor)
#Xtest = select(Xtest, MONTH, OP_UNIQUE_CARRIER) %>% mutate_all(factor)

Ytrain <- factor(select(trainingData, death_yn) %>% unlist())
Ytest  <- factor(select(testingData, death_yn) %>% unlist())
```

```{r catagorical feature dummy encoding}
#train dummy model and apply to predictors
#NOTE: this needs to be changed if we end up using some predictors that are not categorical
XtrainQuant = Xtrain %>% select(Series_Complete_Pop_Pct)
XtestQuant = Xtest %>% select(Series_Complete_Pop_Pct)
XtrainQual = Xtrain %>% select(-c(Series_Complete_Pop_Pct))
XtestQual = Xtest %>% select(-c(Series_Complete_Pop_Pct))


dummyModel <- dummyVars(~ ., data= XtrainQual, fullRank = TRUE)

XtrainD = predict(dummyModel, XtrainQual)
XtestD = predict(dummyModel, XtestQual)

XtrainFull = cbind(XtrainD, XtrainQuant)
XtestFull = cbind(XtestD, XtestQuant)


#We want to be explicit about what is the event and what is not, so we need to relevel
#In the lecture on imbalanced data, prof said that the reference category is treated as the event in the caret package
YtrainRelevel = relevel(Ytrain, ref = 'Yes')
YtestRelevel = relevel(Ytest, ref = 'Yes')
```

### 3.2 Applying Logistic Regression Model:
```{r logistic regression model , cache = TRUE}
#training logistic regression model
trControl = trainControl(method = 'none')
outLogistic = train(x = XtrainFull, y = YtrainRelevel,
                    method = 'glm', trControl = trControl)

YhatTestProbLR = predict(outLogistic, XtestFull, type = 'prob')

```
Let's look at a calibration plot of our probabilities

```{r logistic regression model calibration plot}
calibProbs = calibration(YtestRelevel ~ YhatTestProbLR$Yes, cuts = 5)
xyplot(calibProbs)
```


```{r ROC Curve of logistic regression model}
#generating the roc curve
rocCurveLR = roc(Ytest, YhatTestProbLR$Yes)

#plot the roc
plot(rocCurveLR, legacy.axes=TRUE)

rocCurveLR$auc

```

```{r confusion matrix logistic regression model}
#find threshold by setting based on sensitivity or specificity
thresholdsLR = rocCurveLR$thresholds
pt8 = max(which(rocCurveLR$sensitivities >= 0.8) )
thresholdLR = thresholdsLR[pt8]
specificityLR = rocCurveLR$specificities[pt8]
sensitivityLR = rocCurveLR$sensitivities[pt8]

YhatTestThreshLR = ifelse(YhatTestProbLR$Yes > thresholdLR, 'Yes', 'No') %>% as.factor

confusionMatrixOutLR = confusionMatrix(reference = YtestRelevel, data = YhatTestThreshLR, positive = "Yes")
confusionMatrixOutLR
```

### 3.3 Applying Logistic Elastic Net Model:
```{r logistic elastic net , cache = TRUE}
set.seed(13)
K            = 5
trainControl = trainControl(method = "cv", number = K)
tuneGrid     = expand.grid('alpha'=c(0,.25,.5,.75,1),'lambda' = seq(0, .002, length.out = 15))

elasticOut = train(x = XtrainFull, y = YtrainRelevel,
                   method = "glmnet", 
                   trControl = trainControl, tuneGrid = tuneGrid)

```

```{r logistic elastic net best tune}
#starting to look at the output from the model
#elasticOut$finalModel$beta[,1:6]

#best tune from the model
elasticOut$bestTune

```

```{r logistic elastic net retrain with best tune , cache = TRUE}
#re-train the model using the parameters from the best tune
#releveling the glmnet supervisor because otherwise it doesn't make sense
require(glmnet)
YtrainGLMNet = relevel(YtrainRelevel, ref = 'No')
glmnetOut      = glmnet(x = as.matrix(XtrainFull), y = YtrainGLMNet, s=elasticOut$bestTune$alpha, 
                        family = 'binomial', standardize = FALSE)


probHatTestGlmnet   = predict(glmnetOut, as.matrix(XtrainFull), s=elasticOut$bestTune$lambda, type='response')
YhatTestGlmnet = ifelse(probHatTestGlmnet > 0.035, 'Yes', 'No')
```

Let's make a calibration plot of our probabilities:

```{r logistic elastic net calibration plot}
calibProbsGLMnet = calibration(YtrainRelevel ~ probHatTestGlmnet, cuts = 5)
xyplot(calibProbsGLMnet)
```


```{r logistic elastic net coefficients}
#looking at the coefficients from the best tune
betaHatGlmnet = coef(glmnetOut, s=elasticOut$bestTune$lambda)
betaHatGlmnet
```

```{r logistic elastic net ROC Curve}
#plot ROC curve and get AUC
probHatTestGlmnet = predict(elasticOut, XtestFull, s=elasticOut$bestTune$lambda, type = 'prob')
rocOutGlmnet = roc(response = Ytest, probHatTestGlmnet$Yes)
plot(rocCurveLR, legacy.axes=TRUE)
plot(rocOutGlmnet, col = 'red', add = TRUE)
legend(0.2,0.3, legend=c("LR", "Elastic Net"), col=c("black", "red"), lty = 1, lwd = 3)

# AUC Logistic Elastic Net
rocOutGlmnet$auc

```

```{r logistic elastic net confusion matrix}
YhatTestGlmnet = ifelse(probHatTestGlmnet$Yes > 0.035, 'Yes', 'No')

confusionMatrixOutGlmnet = confusionMatrix(reference = YtestRelevel, data = as.factor(YhatTestGlmnet), positive = "Yes")
confusionMatrixOutGlmnet
```

### 3.4 Applying the LDA model

```{r LDA model}
trControl = trainControl(method = 'none')
outLDA = train(x = XtrainFull, y = YtrainRelevel,
                    method = 'lda', trControl = trControl)

YhatTestProbLDA = predict(outLDA, XtestFull, type = 'prob')
```

Let's look at a calibration plot of our probabilities:

```{r LDA model calibration plot}
#calibration plot for the LDA model
calibProbsLDA = calibration(YtestRelevel ~ YhatTestProbLDA$Yes, cuts = 5)
xyplot(calibProbsLDA)

```

```{r LDA model ROC Curve}
#generating the roc curve
rocCurveLDA = roc(Ytest, YhatTestProbLDA$Yes)

#plot the roc
plot(rocCurveLR, legacy.axes=TRUE)
plot(rocOutGlmnet, col = 'red', add = TRUE)
plot(rocCurveLDA, col = 'blue', add = TRUE)
legend(0.2,0.3, legend=c("LR", "Elastic Net",  "LDA"), col=c("black", "red", "blue"), lty = 1, lwd = 3)

rocCurveLDA$auc
```

```{r LDA model confusion matrix }
#find threshold for .8 sensitivity and generate confusion matrix
thresholdsLDA = rocCurveLDA$thresholds
pt8 = max(which(rocCurveLDA$sensitivities >= 0.80) )
thresholdLDA = thresholdsLDA[pt8]
specificityLDA = rocCurveLDA$specificities[pt8]
sensitivityLDA = rocCurveLDA$sensitivities[pt8]

YhatTestThreshLDA = ifelse(YhatTestProbLDA$Yes > thresholdLDA, 'Yes', 'No') %>% as.factor

confusionMatrixOutLDA = confusionMatrix(reference = YtestRelevel, data = YhatTestThreshLDA, positive = "Yes")
confusionMatrixOutLDA
```



# **4- Remedies for Severe Class Imbalance**

### 4.1 Training with kappa for Severe Class Imbalance

```{r Training with kappa  , cache = TRUE}
trControl = trainControl(method = 'cv')
tuneGrid = data.frame('nrounds'= seq(100,500,length.out = 10),
                        'max_depth' = 2,
                        'eta' = .01,
                        'gamma' = 0,
                        'colsample_bytree' = 1,
                        'min_child_weight' = 0,
                        'subsample' = .5)
boostKappaOut = train(x = XtrainFull, y = YtrainRelevel,
                     method = "xgbTree", 
                     tuneGrid = tuneGrid,
                     metric = 'Kappa',
                     trControl = trControl)
boostOut      = train(x = XtrainFull, y = YtrainRelevel,
                     method = "xgbTree", 
                     tuneGrid = tuneGrid,
                     metric = 'Accuracy',
                     trControl = trControl)

YhatTestBoostKappa = predict(boostKappaOut, XtestFull)
YhatTestBoost      = predict(boostOut, XtestFull)


confusionMatrixOutBoost = confusionMatrix(reference = YtestRelevel, data = YhatTestBoost, positive = "Yes")
confusionMatrixOutBoost
confusionMatrixOutBoostKappa = confusionMatrix(reference = YtestRelevel, data = YhatTestBoostKappa, positive = "Yes")
confusionMatrixOutBoostKappa
```
### 4.2 Random Forest via the Ranger package

```{r Random Forest  , cache = TRUE}
tuneGrid = data.frame('mtry' = 1:2,
                      'splitrule' = 'gini',
                      'min.node.size' = 1)

rfOut   = train(x = XtrainFull, y = YtrainRelevel,
                     method = "ranger", 
                     tuneGrid = tuneGrid,
                     metric = 'Kappa',
                     trControl = trControl)
YhatTestRf  = predict(rfOut, XtestFull)

confusionMatrixOutRF = confusionMatrix(reference = YtestRelevel, data = YhatTestRf, positive = "Yes")
confusionMatrixOutRF
```


### 4.3 Adjusting threshold
```{r Adjusting threshold}
require(pROC)

pHat   = predict(boostOut, XtestFull, type = 'prob')
rocOut = roc(YtestRelevel,pHat[,1],levels=c('0','1'))
plot(rocOut, print.thres = c(.1,.25,.5), 
     legacy.axes = TRUE, print.thres.cex=.65)
table(YhatTestBoost,YtestRelevel)

```



```{r knit stop}
knitr::knit_exit()
```


