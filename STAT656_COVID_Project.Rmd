---
title: 'STAT656_COVID_Project'
output:
  html_document: default
---

# Loading packages and Dataset
```{r loadingPackages}
packs = c('dplyr','ggplot2', 'caret','corrplot', 'e1071','readr', 'pROC', 'lubridate')
lapply(packs,require,character.only=TRUE)
```

```{r loadingData , cache = TRUE}
#rm(list=ls())# Just to clean up the memory again

# original data from (https://data.cdc.gov/Case-Surveillance/COVID-19-Case-Surveillance-Public-Use-Data-with-Ge/n8mc-b4w4) is ~85+ million rows and ~13GB file size

# filtered data (https://data.cdc.gov/Case-Surveillance/COVID-19-Case-Surveillance-Public-Use-Data-with-Ge/n8mc-b4w4/data) is ~1.4+ million rows and ~200MB file size - removing (missing, NA, unknown) from the following columns:
# death_yn, age_group, hosp_yn,  underlying_conditions_yn, 

# "dataSetPath" is the path to the directory on your PC where you  place the dataset csv file 
#dataSetPath = '/home/yako/Desktop/TAMU_STAT/STAT656_Applied Analytics/STAT656FinalProject/Datasets'
dataSetPathL = '../'
dataSetPath = '/home/yako/Desktop/TAMU_STAT/STAT656_Applied Analytics/STAT656FinalProject/Datasets'
dataSetName = 'COVID-19_Case_Surveillance_Public_Use_Data_with_Geography_Filterd.csv'
dataSet     = read_csv(file.path(dataSetPathL,dataSetName))
```
# Exploratory Data Analysis
Items that usually need to be checked:

* Data structures
* Checking for missing data
* Converting qualitative features to dummy variables
* Extreme observations
* Skewness/transformations
* Correlations

### Checking the overall structure and properties of the dataset
```{r Check data structures}
str(dataSet)
```
```{r Check number of unique values}
rbind(sapply(dataSet,function(x){ length(unique(x))}),
      sapply(dataSet,class))
```

### Checking for missing values
```{r Check if any features have NA}
sapply(dataSet, function(x) sum(is.na(x)))
```

### Creating conditional frequency plots and frequency tables
- Here we build a function to loop through the categorical features a plot frequency charts of their levels conditioned on the levels of our response variable
```{r plot feature, fig.align="center", fig.width = 12 , cache = TRUE}
require(gridExtra)
theme_update(plot.title = element_text(hjust = 0.5))

# Extracting features that have "character" or "factor" type
catFteaures = names(dataSet[, sapply(dataSet, class) %in% c('character', 'factor')])[-c(1,2,3,4,5,16)]

# Loop through selected categorical features and plot 
for (colname in catFteaures) {
  
  plot1 = ggplot(filter(dataSet,death_yn == "No" ), aes(x=reorder(.data[[colname]], .data[[colname]], function(x)-length(x)))) + geom_bar(fill="#3A5795") +  labs(x=colname) + labs(title = paste("Counts of", colname, "when:", "\n", "death_yn" , "=", "No" ))
  
  plot2 = ggplot(filter(dataSet,death_yn == "Yes" ), aes(x=reorder(.data[[colname]], .data[[colname]], function(x)-length(x)))) + geom_bar(fill="#c00000") +  labs(x=colname) + labs(title = paste("Counts of", colname, "when:", "\n", "death_yn" , "=", "Yes" ))
  
  grid.arrange(plot1, plot2, ncol=2)
}

# Loop through selected categorical features and print frequency tables
for (colname in catFteaures){
  print(table(dataSet[colname]))
  print("------------------------------")
}

```

Note from Laura: This underlying_conditions_yn column might be problematic


# Loading in Vaccination Data as a potential predictor

```{r load in the vaccination data}
vaxSetPathL = '../'
vaxSetName = 'COVID-19_Vaccinations_in_the_United_States_County.csv'
vaxSet     = read_csv(file.path(vaxSetPathL,vaxSetName))
```

```{r filtering columns}
#filtering out most of the columns and just keeping what we need
vaxSet = vaxSet %>% select(c(Date, FIPS, Series_Complete_Pop_Pct, Census2019, Census2019_65PlusPop))

```


```{r formatting date to fit our COVID case dataset}
vaxSet$Day = as.numeric(format(as.Date(vaxSet$Date,format="%m/%d/%Y"), format = "%d"))
vaxSet$Date = format(as.Date(vaxSet$Date,format="%m/%d/%Y"), format = "%Y-%m")
```

I'm going to take the number from the end of the month in order to get it to work with our data

```{r group by for each month}
vaxSet = vaxSet %>% group_by(Date, FIPS) %>% summarize(Series_Complete_Pop_Pct = max(Series_Complete_Pop_Pct),
                                                       Census2019 = max(Census2019),
                                                       Census2019_65PlusPop = max(Census2019_65PlusPop))
```

```{r adjust date from original dataset}
#adding the first to these dates so that we can use this as a date
dataSet$vax_data_month = as.Date(paste(dataSet$case_month,"-01",sep=""))
```

```{r adjust date from vax dataset}
#this gives you the date where the vax data is considered to be valid 
vaxSet$Date = as.Date(paste(vaxSet$Date,"-01",sep="")) %m+% months(1)
```


Joining in the vaccination data and adding a roll-out indicator
```{r}
#join where the date of the case is in the month where vaccination percentage is valid
fullSet = dataSet %>% left_join(vaxSet, by=c('county_fips_code' = 'FIPS', 'vax_data_month' = 'Date'))

#zero out entries before there was widespread vaccination roll-out
fullSet$Series_Complete_Pop_Pct = ifelse(full_set$vax_data_month <= '2020-12-31', 0, full_set$Series_Complete_Pop_Pct)

#create an indicator variable for vaccination roll-out
fullSet$vax_rollout_indicator = ifelse(full_set$vax_data_month <= '2020-12-31', 0, 1)
```

```{r}

```

# Taking the states and grouping them into regions for potential predictors

```{r}
#filtering out Guam observations
fullSet = fullSet %>% filter(res_state != 'GU', res_state != 'PR', res_state != 'VI')

#Using the census-bureau designations: https://en.wikipedia.org/wiki/List_of_regions_of_the_United_States#Census_Bureau-designated_regions_and_divisions

fullSet$region = ifelse(fullSet$res_state %in% c('CT', 'ME', 'VT', 'NH', 'VT', 'MA', 'RI', 'NY', 'PA', 'NJ'), 'NorthEast',
                        ifelse(fullSet$res_state %in% c('IL', 'IN', 'MI', 'OH', 'WI', 'IA', 'KS', 'MN', 'MO', 'NE', 'ND', 'SD'), 'Midwest',
                               ifelse(fullSet$res_state %in% c('DE', 'FL', 'GA', 'MD', 'NC', 'SC', 'VA', 'DC', 'WV', 'AL', 'KY', 'MS', 'TN', 'AR', 'LA', 'OK', 'TX'), 'South',
                                      ifelse(fullSet$res_state %in% c('AZ', 'CO', 'ID', 'MT', 'NV', 'NM', 'UT', 'WY', 'AK', 'CA', 'HI', 'OR', 'WA'), 'West', 'N/A'))))

```


# Prepping Data for Modeling:

```{r data prep}
#partition data into train / test split
set.seed(13)
trainingDataIndex <- createDataPartition(dataSet$death_yn, p=.7, list=FALSE)
trainingData <- dataSet[trainingDataIndex,]
testingData <- dataSet[-trainingDataIndex,]

#split predictors and supervisor variable
Xtrain <- select(trainingData, -death_yn)
Xtest  <- select(testingData, -death_yn)
Ytrain <- factor(select(trainingData, death_yn) %>% unlist())
Ytest  <- factor(select(testingData, death_yn) %>% unlist())

#train dummy model and apply to predictors
#NOTE: this needs to be changed if we end up using some predictors that are not categorical
dummyModel <- dummyVars(~ ., data= Xtrain, fullRank = TRUE)

XtrainFull = predict(dummyModel, Xtrain)
XtestFull = predict(dummyModel, Xtest)

#We want to be explicit about what is the event and what is not, so we need to relevel
#NOTE: I'm not sure about this, but I think we DON'T want the event as the reference category. This may be incorrect
YtrainRelevel = relevel(Ytrain, ref = 'No')
YtestRelevel = relevel(Ytest, ref = 'No')

```



# Building Models:

=======

```{r logistic regression model}
#training logistic regression model
trControl = trainControl(method = 'none')
outLogistic = train(x = XtrainFull, y = YtrainRelevel,
                    method = 'glm', trControl = trControl)

YhatTestProb = predict(outLogistic, XtestFull, type = 'prob')

```

```{r logistic regression model}
#generating the roc curve
rocCurve = roc(Ytest, YhatTestProb$Yes)

#plot the roc
plot(rocCurve, legacy.axes=TRUE)

rocCurve$auc
```

```{r logistic regression model}
#find threshold by setting based on sensitivity or specificity
thresholds = rocCurve$thresholds
pt8 = max(which(rocCurve$sensitivities >= 0.80) )
threshold = thresholds[pt8]
specificity = rocCurve$specificities[pt8]
sensitivity = rocCurve$sensitivities[pt8]

YhatTestThresh = ifelse(YhatTestProb$Yes > threshold,
                        'Yes', 'No') %>% as.factor

confusionMatrixOut = confusionMatrix(reference = YtestRelevel, data = YhatTestThresh)
confusionMatrixOut
```

```{r}

```

```{r logistic elastic net}
set.seed(13)
K            = 10
trainControl = trainControl(method = "cv", number = K)
tuneGrid     = expand.grid('alpha'=c(0,.25,.5,.75,1),'lambda' = seq(00, .001, length.out = 30))

elasticOut = train(x = XtrainFull, y = YtrainRelevel,
                   method = "glmnet", 
                   trControl = trainControl, tuneGrid = tuneGrid)

```

```{r logistic elastic net}
#starting to look at the output from the model
elasticOut$finalModel$beta[,1:6]

#best tune from the model
elasticOut$bestTune

```

```{r logistic elastic net}
#re-train the model using the parameters from the best tune
require(glmnet)
glmnetOut      = glmnet(x = as.matrix(XtrainFull), y = YtrainRelevel, s=elasticOut$bestTune$alpha, 
                        family = 'binomial', standardize = FALSE)
probHatTest    = predict(glmnetOut, XtestFull, s=elasticOut$bestTune$lambda, type='response')
YhatTestGlmnet = ifelse(probHatTest > 0.035, 'Yes', 'No')
```

```{r logistic elastic net}
#looking at the coefficients from the best tune
betaHat = coef(glmnetOut, s=elasticOut$bestTune$lambda)
betaHat

#get the accuracy 
mean(YhatTestGlmnet == YtestRelevel)
```

```{r logistic elastic net}
#plot ROC curve and get AUC
probHatTest = predict(elasticOut, XtestFull, s=elasticOut$bestTune$lambda, type = 'prob')
rocOut = roc(response = YtestRelevel, probHatTest$Yes)

plot(rocOut)

rocOut$auc

```

```{r logistic elastic net}
confusionMatrixOut = confusionMatrix(reference = YtestRelevel, data = as.factor(YhatTestGlmnet))
confusionMatrixOut
```

